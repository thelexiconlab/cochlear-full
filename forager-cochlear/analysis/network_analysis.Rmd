---
title: "Cochlear Analysis"
author: "Channing Hambric"
date: "2024-09-30"
output:
  html_document: default
  pdf_document: default
---

###THIS STILL NEEDS TO BE CLEANED UP


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

#Libraries
```{r}
library(tidyverse)
library(ggthemes)
library(igraph)
```
# import data
```{r}

#For assigning CI/NH status
participant_groupings <- read.csv("../participant_groupings.csv")

#using best fit structure for each group
semantics<-read.csv("best_indv_model_lexical.csv") %>% select(Subject,Group,domain,Fluency_Item,structure,semantic,phonological,frequency,alpha)

semantics_overall<-semantics%>%
  group_by(Subject) %>% mutate(item = row_number()) %>%
  left_join(participant_groupings) %>%
  mutate(Frequency_Value = frequency/100,
         Phonological_Similarity = ifelse(phonological == 0.0001, 0, phonological),alpha_recoded = ifelse(alpha > 0.4, "high alpha", "low alpha"))


blended_nh_animals<-semantics %>%filter(Group=="NH",domain=="animals")%>%
  rename(blended = semantic) %>% 
  group_by(Subject) %>% mutate(item = row_number()) %>%
  left_join(participant_groupings) %>%
  mutate(Frequency_Value = frequency/100,
         Phonological_Similarity = ifelse(phonological == 0.0001, 0, phonological),alpha_recoded = ifelse(alpha > 0.4, "high alpha", "low alpha"))

blended_ci_animals<-semantics %>%filter(Group=="CI",domain=="animals")%>%
  rename(blended = semantic) %>% 
  group_by(Subject) %>% mutate(item = row_number()) %>%
  left_join(participant_groupings) %>%
  mutate(Frequency_Value = frequency/100,
         Phonological_Similarity = ifelse(phonological == 0.0001, 0, phonological),alpha_recoded = ifelse(alpha > 0.4, "high alpha", "low alpha"))



blended_nh_foods<-semantics %>%filter(Group=="NH",domain=="foods")%>%
  rename(blended = semantic) %>% 
  group_by(Subject) %>% mutate(item = row_number()) %>%
  left_join(participant_groupings) %>%
  mutate(Frequency_Value = frequency/100,
         Phonological_Similarity = ifelse(phonological == 0.0001, 0, phonological),alpha_recoded = ifelse(alpha > 0.4, "high alpha", "low alpha"))

blended_ci_foods<-semantics %>%filter(Group=="CI",domain=="foods")%>%
  rename(blended = semantic) %>% 
  group_by(Subject) %>% mutate(item = row_number()) %>%
  left_join(participant_groupings) %>%
  mutate(Frequency_Value = frequency/100,
         Phonological_Similarity = ifelse(phonological == 0.0001, 0, phonological),alpha_recoded = ifelse(alpha > 0.4, "high alpha", "low alpha"))


```
# create edges

```{r}
library(igraph)
library(dplyr)

# Function to create a well-formatted network graph
create_graph <- function(df, group_label, similarity_metric) {
  
   # Filter for the given group
  edges <- df %>%
    filter(Group == group_label) %>%
    group_by(Subject) %>%
    mutate(Next_Word = lag(Fluency_Item)) %>%
    na.omit() %>%
    ungroup() %>%
    transmute(From = Fluency_Item, 
              To = Next_Word, 
              Weight = .data[[similarity_metric]]) %>%
    filter(Weight > 0) %>% distinct()
  
  # Create graph
  g <- graph_from_data_frame(edges, directed = FALSE)
  
  # Compute network metrics
  avg_path_length <- mean_distance(g, directed = FALSE, unconnected = TRUE)  # Handle disconnected components
  clustering_coeff <- transitivity(g, type = "global")  # Global clustering coefficient
  graph_density <- edge_density(g)  # Density of the graph
  degree_centrality <- degree(g)  # Number of connections per node
  
  # Print network metrics
  cat("\nNetwork Metrics for Group:", group_label, "(", similarity_metric, ")\n")
  cat("---------------------------------------------------\n")
  cat("Average Shortest Path Length:", round(avg_path_length, 3), "\n")
  cat("Clustering Coefficient:", round(clustering_coeff, 3), "\n")
  cat("Graph Density:", round(graph_density, 3), "\n")
  cat("Top 5 Most Central Nodes (by Degree):\n")
  print(sort(degree_centrality, decreasing = TRUE)[1:5])

  # Improve layout
  set.seed(42)  # Ensure consistent layout
  layout <- layout_with_fr(g)  # Force-directed layout

  # Plot graph with improved aesthetics
  plot(g, 
       layout = layout,
       edge.width = E(g)$Weight * 3,  # Scale edge width
       vertex.label.cex = 0.7,  # Reduce label size
       vertex.label.dist = 1,  # Push labels away from nodes
       vertex.color = ifelse(group_label == "NH", "skyblue", "forestgreen"),  # Color nodes by group
       vertex.frame.color = "gray30",
       edge.color = "gray70",
       vertex.size = 2,
       main = paste("Network - Group", group_label, similarity_metric))
}

# Example usage:
#create_graph(blended_nh_animals, "NH", "blended")
```


```{r}

#alpha group counts
semantics_overall %>%
  group_by(Group,domain,alpha_recoded) %>%
  summarise(Unique_Subjects = n_distinct(Subject))


#overall semantic networks for NH vs CI for each domain
#animals
create_graph(blended_nh_animals, "NH", "blended")
create_graph(blended_ci_animals, "CI", "blended")
#higher CC for CIs? idk if sig

#foods
create_graph(blended_nh_foods, "NH", "blended")
create_graph(blended_ci_foods, "CI", "blended")
#higher CC for NHs


#overall phonological networks for NH vs CI for each domain
#animals
create_graph(blended_nh_animals, "NH", "Phonological_Similarity")
create_graph(blended_ci_animals, "CI", "Phonological_Similarity")
#much higher CC for NH

#foods
create_graph(blended_nh_foods, "NH", "Phonological_Similarity")
create_graph(blended_ci_foods, "CI", "Phonological_Similarity")
#much higher CC for NH





#looking at semantic graph density by alpha - is weighting more s2v assc with a more or less connected network
#data a bit sparse though
#animals
create_graph(blended_nh_animals %>%filter(alpha_recoded=="low alpha"), "NH", "blended")
create_graph(blended_nh_animals %>%filter(alpha_recoded=="high alpha"), "NH", "blended")
#higher clustering coefficient and density for higher alphas (more s2v)

create_graph(blended_ci_animals %>%filter(alpha_recoded=="low alpha"), "CI", "blended")
create_graph(blended_ci_animals %>%filter(alpha_recoded=="high alpha"), "CI", "blended")
#higher clustering coefficient for higher alphas

#foods
create_graph(blended_nh_foods %>%filter(alpha_recoded=="low alpha"), "NH", "blended")
create_graph(blended_nh_foods %>%filter(alpha_recoded=="high alpha"), "NH", "blended")
#less clustered and less dense for high alphas
#maybe using more single item cues?

create_graph(blended_ci_foods %>%filter(alpha_recoded=="low alpha"), "CI", "blended")
create_graph(blended_ci_foods %>%filter(alpha_recoded=="high alpha"), "CI", "blended")
#slightly higher CC for high alphas



#looking at phonology

#animals
create_graph(blended_nh_animals %>%filter(alpha_recoded=="low alpha"), "NH", "Phonological_Similarity")
create_graph(blended_nh_animals %>%filter(alpha_recoded=="high alpha"), "NH", "Phonological_Similarity")
#slightly  larger clustering coefficient for high alpha

create_graph(blended_ci_animals %>%filter(alpha_recoded=="low alpha"), "CI", "Phonological_Similarity")
create_graph(blended_ci_animals %>%filter(alpha_recoded=="high alpha"), "CI", "Phonological_Similarity")
#not much going on

#foods
create_graph(blended_nh_foods %>%filter(alpha_recoded=="low alpha"), "NH", "Phonological_Similarity")
create_graph(blended_nh_foods %>%filter(alpha_recoded=="high alpha"), "NH", "Phonological_Similarity")
#larger ASPL for high alphas, slightly higher CC

create_graph(blended_ci_foods %>%filter(alpha_recoded=="low alpha"), "CI", "Phonological_Similarity")
create_graph(blended_ci_foods %>%filter(alpha_recoded=="high alpha"), "CI", "Phonological_Similarity")
#larger ASPL for high alpha, higher CC, but low alpha more dense
```


