---
title: "Cochlear Analysis"
author: "Channing Hambric"
date: "2024-09-30"
output:
  html_document: default
  pdf_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

#Libraries
```{r}
library(tidyverse)
library(ggthemes)
library(purrr)
library(ggpubr)
library(lubridate)
library(dplyr)
library(ggplot2)
library(hrbrthemes)
library(tidyboot)
library(gridExtra)
library(lme4)
library(emmeans)
library(data.table)
library(paletteer)
library(forcats)
library(knitr)
```

#Importing Fluency/Clustering Data

```{r}
#For assigning CI/NH status
participant_groupings <- read.csv("../participant_groupings.csv")

#Animals
#Animals - W2V 50 dim
animals_50_w2v_fluency <- read.csv("../output/animals/word2vec/50/individual_descriptive_stats.csv") %>%mutate("dimension"="50") %>% mutate("struct" = "w2v")
#Animals - W2V 100 dim
animals_100_w2v_fluency <- read.csv("../output/animals/word2vec/100/individual_descriptive_stats.csv")%>%mutate("dimension"="100") %>% mutate("struct" = "w2v")
#Animals - W2V 200 dim
animals_200_w2v_fluency <- read.csv("../output/animals/word2vec/200/individual_descriptive_stats.csv")%>%mutate("dimension"="200") %>% mutate("struct" = "w2v")
#Animals - W2V 300 dim
animals_300_w2v_fluency <- read.csv("../output/animals/word2vec/300/individual_descriptive_stats.csv")%>%mutate("dimension"="300") %>% mutate("struct" = "w2v")
#Animals - S2V 50 dim
animals_50_s2v_fluency <- read.csv("../output/animals/speech2vec/50/individual_descriptive_stats.csv")%>%mutate("dimension"="50") %>% mutate("struct" = "s2v")
#Animals - S2V 100 dim
animals_100_s2v_fluency <- read.csv("../output/animals/speech2vec/100/individual_descriptive_stats.csv")%>%mutate("dimension"="100") %>% mutate("struct" = "s2v")
#Animals - S2V 200 dim
animals_200_s2v_fluency <- read.csv("../output/animals/speech2vec/200/individual_descriptive_stats.csv")%>%mutate("dimension"="200") %>% mutate("struct" = "s2v")
#Animals - S2V 300 dim
animals_300_s2v_fluency <- read.csv("../output/animals/speech2vec/300/individual_descriptive_stats.csv")%>%mutate("dimension"="300") %>% mutate("struct" = "s2v")

full_animals_fluency = rbind(animals_50_w2v_fluency,animals_100_w2v_fluency,animals_200_w2v_fluency,animals_300_w2v_fluency,animals_50_s2v_fluency,animals_100_s2v_fluency,animals_200_s2v_fluency,animals_300_s2v_fluency)

#Linking participant groupings
full_animals_fluency = full_animals_fluency %>%
   mutate("domain"="animals") %>%
    left_join(participant_groupings) %>% filter(!is.na(Group)) %>%
  mutate(Group = fct_recode(Group, "normal hearing" = "NH", "cochlear implant" = "CI"),
         Group = fct_relevel(Group, "normal hearing", "cochlear implant"))%>%
  rename("Numb_of_Items"="X._of_Items")

#Foods
#Foods - W2V 50 dim
foods_50_w2v_fluency <- read.csv("../output/foods/word2vec/50/individual_descriptive_stats.csv") %>%mutate("dimension"="50") %>% mutate("struct" = "w2v")
#Foods - W2V 100 dim
foods_100_w2v_fluency <- read.csv("../output/foods/word2vec/100/individual_descriptive_stats.csv")%>%mutate("dimension"="100") %>% mutate("struct" = "w2v")
#Foods - W2V 200 dim
foods_200_w2v_fluency <- read.csv("../output/foods/word2vec/200/individual_descriptive_stats.csv")%>%mutate("dimension"="200") %>% mutate("struct" = "w2v")
#Foods - W2V 300 dim
foods_300_w2v_fluency <- read.csv("../output/foods/word2vec/300/individual_descriptive_stats.csv")%>%mutate("dimension"="300") %>% mutate("struct" = "w2v")
#Foods - S2V 50 dim
foods_50_s2v_fluency <- read.csv("../output/foods/speech2vec/50/individual_descriptive_stats.csv")%>%mutate("dimension"="50") %>% mutate("struct" = "s2v")
#Foods - S2V 100 dim
foods_100_s2v_fluency <- read.csv("../output/foods/speech2vec/100/individual_descriptive_stats.csv")%>%mutate("dimension"="100") %>% mutate("struct" = "s2v")
#Foods - S2V 200 dim
foods_200_s2v_fluency <- read.csv("../output/foods/speech2vec/200/individual_descriptive_stats.csv")%>%mutate("dimension"="200") %>% mutate("struct" = "s2v")
#Foods - S2V 300 dim
foods_300_s2v_fluency <- read.csv("../output/foods/speech2vec/300/individual_descriptive_stats.csv")%>%mutate("dimension"="300") %>% mutate("struct" = "s2v")

full_foods_fluency = rbind(foods_50_w2v_fluency,foods_100_w2v_fluency,foods_200_w2v_fluency,foods_300_w2v_fluency,foods_50_s2v_fluency,foods_100_s2v_fluency,foods_200_s2v_fluency,foods_300_s2v_fluency)

#Linking participant groupings
full_foods_fluency = full_foods_fluency%>%
    mutate("domain"="foods") %>%
    left_join(participant_groupings) %>% filter(!is.na(Group)) %>%
  mutate(Group = fct_recode(Group, "normal hearing" = "NH", "cochlear implant" = "CI"),
         Group = fct_relevel(Group, "normal hearing", "cochlear implant")) %>%
  rename("Numb_of_Items"="X._of_Items")
```

#Importing Lexical Data
```{r}
#Animals
#Animals - W2V 50 dim
animals_50_w2v_lexical <- read.csv("../output/animals/word2vec/50/lexical_results.csv") %>%mutate("dimension"="50") %>% mutate("struct" = "w2v")
#Animals - W2V 100 dim
animals_100_w2v_lexical <- read.csv("../output/animals/word2vec/100/lexical_results.csv")%>%mutate("dimension"="100") %>% mutate("struct" = "w2v")
#Animals - W2V 200 dim
animals_200_w2v_lexical <- read.csv("../output/animals/word2vec/200/lexical_results.csv")%>%mutate("dimension"="200") %>% mutate("struct" = "w2v")
#Animals - W2V 300 dim
animals_300_w2v_lexical <- read.csv("../output/animals/word2vec/300/lexical_results.csv")%>%mutate("dimension"="300") %>% mutate("struct" = "w2v")
#Animals - S2V 50 dim
animals_50_s2v_lexical <- read.csv("../output/animals/speech2vec/50/lexical_results.csv")%>%mutate("dimension"="50") %>% mutate("struct" = "s2v")
#Animals - S2V 100 dim
animals_100_s2v_lexical <- read.csv("../output/animals/speech2vec/100/lexical_results.csv")%>%mutate("dimension"="100") %>% mutate("struct" = "s2v")
#Animals - S2V 200 dim
animals_200_s2v_lexical <- read.csv("../output/animals/speech2vec/200/lexical_results.csv")%>%mutate("dimension"="200") %>% mutate("struct" = "s2v")
#Animals - S2V 300 dim
animals_300_s2v_lexical <- read.csv("../output/animals/speech2vec/300/lexical_results.csv")%>%mutate("dimension"="300") %>% mutate("struct" = "s2v")

full_animals_lexical = rbind(animals_50_w2v_lexical,animals_100_w2v_lexical,animals_200_w2v_lexical,animals_300_w2v_lexical,animals_50_s2v_lexical,animals_100_s2v_lexical,animals_200_s2v_lexical,animals_300_s2v_lexical)

#Linking participant groupings
full_animals_lexical = full_animals_lexical %>%
   mutate("domain"="animals") %>%
    left_join(participant_groupings) %>% filter(!is.na(Group)) %>%
  mutate(Group = fct_recode(Group, "normal hearing" = "NH", "cochlear implant" = "CI"),
         Group = fct_relevel(Group, "normal hearing", "cochlear implant"))
#Foods
#Foods - W2V 50 dim
foods_50_w2v_lexical <- read.csv("../output/foods/word2vec/50/lexical_results.csv") %>%mutate("dimension"="50") %>% mutate("struct" = "w2v")
#Foods - W2V 100 dim
foods_100_w2v_lexical <- read.csv("../output/foods/word2vec/100/lexical_results.csv")%>%mutate("dimension"="100") %>% mutate("struct" = "w2v")
#Foods - W2V 200 dim
foods_200_w2v_lexical <- read.csv("../output/foods/word2vec/200/lexical_results.csv")%>%mutate("dimension"="200") %>% mutate("struct" = "w2v")
#Foods - W2V 300 dim
foods_300_w2v_lexical <- read.csv("../output/foods/word2vec/300/lexical_results.csv")%>%mutate("dimension"="300") %>% mutate("struct" = "w2v")
#Foods - S2V 50 dim
foods_50_s2v_lexical <- read.csv("../output/foods/speech2vec/50/lexical_results.csv")%>%mutate("dimension"="50") %>% mutate("struct" = "s2v")
#Foods - S2V 100 dim
foods_100_s2v_lexical <- read.csv("../output/foods/speech2vec/100/lexical_results.csv")%>%mutate("dimension"="100") %>% mutate("struct" = "s2v")
#Foods - S2V 200 dim
foods_200_s2v_lexical <- read.csv("../output/foods/speech2vec/200/lexical_results.csv")%>%mutate("dimension"="200") %>% mutate("struct" = "s2v")
#Foods - S2V 300 dim
foods_300_s2v_lexical <- read.csv("../output/foods/speech2vec/300/lexical_results.csv")%>%mutate("dimension"="300") %>% mutate("struct" = "s2v")

full_foods_lexical = rbind(foods_50_w2v_lexical,foods_100_w2v_lexical,foods_200_w2v_lexical,foods_300_w2v_lexical,foods_50_s2v_lexical,foods_100_s2v_lexical,foods_200_s2v_lexical,foods_300_s2v_lexical)

#Linking participant groupings
full_foods_lexical = full_foods_lexical %>%
  mutate("domain"="foods") %>%
    left_join(participant_groupings) %>% filter(!is.na(Group)) %>%
  mutate(Group = fct_recode(Group, "normal hearing" = "NH", "cochlear implant" = "CI"),
         Group = fct_relevel(Group, "normal hearing", "cochlear implant")) 
```
#Importing USE lexical data
```{r}
animals_USE_lexical <- read.csv("../output/animals/USE/lexical_results.csv") %>%mutate("dimension"="512") %>% mutate("struct" = "USE")%>% mutate("domain" = "animals")
#Foods - W2V 100 dim
foods_USE_lexical <- read.csv("../output/foods/USE/lexical_results.csv")%>%mutate("dimension"="512") %>% mutate("struct" = "USE")%>% mutate("domain" = "foods")

full_USE_lexical<-rbind(animals_USE_lexical,foods_USE_lexical)
full_USE_lexical = full_USE_lexical %>%
    left_join(participant_groupings) %>% filter(!is.na(Group)) %>%
  mutate(Group = fct_recode(Group, "normal hearing" = "NH", "cochlear implant" = "CI"),
         Group = fct_relevel(Group, "normal hearing", "cochlear implant")) 
```


#Importing Model Results - S2V & W2V Only for now
```{r}
#Animals
#Animals - W2V 50 dim
animals_50_w2v_model <- read.csv("../output/animals/word2vec/50/model_results.csv") %>%mutate("dimension"="50") %>% mutate("struct" = "w2v")
#Animals - W2V 100 dim
animals_100_w2v_model <- read.csv("../output/animals/word2vec/100/model_results.csv")%>%mutate("dimension"="100") %>% mutate("struct" = "w2v")
#Animals - W2V 200 dim
animals_200_w2v_model <- read.csv("../output/animals/word2vec/200/model_results.csv")%>%mutate("dimension"="200") %>% mutate("struct" = "w2v")
#Animals - W2V 300 dim
animals_300_w2v_model <- read.csv("../output/animals/word2vec/300/model_results.csv")%>%mutate("dimension"="300") %>% mutate("struct" = "w2v")
#Animals - S2V 50 dim
animals_50_s2v_model <- read.csv("../output/animals/speech2vec/50/model_results.csv")%>%mutate("dimension"="50") %>% mutate("struct" = "s2v")
#Animals - S2V 100 dim
animals_100_s2v_model <- read.csv("../output/animals/speech2vec/100/model_results.csv")%>%mutate("dimension"="100") %>% mutate("struct" = "s2v")
#Animals - S2V 200 dim
animals_200_s2v_model <- read.csv("../output/animals/speech2vec/200/model_results.csv")%>%mutate("dimension"="200") %>% mutate("struct" = "s2v")
#Animals - S2V 300 dim
animals_300_s2v_model <- read.csv("../output/animals/speech2vec/300/model_results.csv")%>%mutate("dimension"="300") %>% mutate("struct" = "s2v")

full_animals_model = rbind(animals_50_w2v_model,animals_100_w2v_model,animals_200_w2v_model,animals_300_w2v_model,animals_50_s2v_model,animals_100_s2v_model,animals_200_s2v_model,animals_300_s2v_model)

#Linking participant groupings
full_animals_model = full_animals_model %>%
   mutate("domain"="animals") %>%
    left_join(participant_groupings) %>% filter(!is.na(Group)) %>%
  mutate(Group = fct_recode(Group, "normal hearing" = "NH", "cochlear implant" = "CI"),
         Group = fct_relevel(Group, "normal hearing", "cochlear implant"))
#Foods
#Foods - W2V 50 dim
foods_50_w2v_model <- read.csv("../output/foods/word2vec/50/model_results.csv") %>%mutate("dimension"="50") %>% mutate("struct" = "w2v")
#Foods - W2V 100 dim
foods_100_w2v_model <- read.csv("../output/foods/word2vec/100/model_results.csv")%>%mutate("dimension"="100") %>% mutate("struct" = "w2v")
#Foods - W2V 200 dim
foods_200_w2v_model <- read.csv("../output/foods/word2vec/200/model_results.csv")%>%mutate("dimension"="200") %>% mutate("struct" = "w2v")
#Foods - W2V 300 dim
foods_300_w2v_model <- read.csv("../output/foods/word2vec/300/model_results.csv")%>%mutate("dimension"="300") %>% mutate("struct" = "w2v")
#Foods - S2V 50 dim
foods_50_s2v_model <- read.csv("../output/foods/speech2vec/50/model_results.csv")%>%mutate("dimension"="50") %>% mutate("struct" = "s2v")
#Foods - S2V 100 dim
foods_100_s2v_model <- read.csv("../output/foods/speech2vec/100/model_results.csv")%>%mutate("dimension"="100") %>% mutate("struct" = "s2v")
#Foods - S2V 200 dim
foods_200_s2v_model <- read.csv("../output/foods/speech2vec/200/model_results.csv")%>%mutate("dimension"="200") %>% mutate("struct" = "s2v")
#Foods - S2V 300 dim
foods_300_s2v_model <- read.csv("../output/foods/speech2vec/300/model_results.csv")%>%mutate("dimension"="300") %>% mutate("struct" = "s2v")

full_foods_model = rbind(foods_50_w2v_model,foods_100_w2v_model,foods_200_w2v_model,foods_300_w2v_model,foods_50_s2v_model,foods_100_s2v_model,foods_200_s2v_model,foods_300_s2v_model)

#Linking participant groupings
full_foods_model = full_foods_model %>%
  mutate("domain"="foods") %>%
    left_join(participant_groupings) %>% filter(!is.na(Group)) %>%
  mutate(Group = fct_recode(Group, "normal hearing" = "NH", "cochlear implant" = "CI"),
         Group = fct_relevel(Group, "normal hearing", "cochlear implant"))
```


#Fluency Analyses
```{r}
#ANIMALS 
animals_fluency<- full_animals_fluency%>% drop_na()

#Getting average fluency per participant
average_animals_fluency = animals_fluency %>% group_by(Subject,Group) %>%
  summarise(average_animals_fluency_count= mean(Numb_of_Items))

#Getting average fluency per group
animals_group_fluency = average_animals_fluency %>%
  group_by(Group) %>%
  summarise(
    fluency_mean = mean(average_animals_fluency_count),
    fluency_sd = sd(average_animals_fluency_count))
kable(animals_group_fluency)

#Does fluency score differ by Group 
animals_group_lm = lmer(data = animals_fluency, Numb_of_Items~ Group + (1|Subject))
summary(animals_group_lm)
car::Anova(animals_group_lm)

animals_numb<-animals_fluency  %>%
  group_by(Group) %>% tidyboot_mean(Numb_of_Items, nboot = 1000, na.rm = T) %>% 
  ggplot(aes(x = Group, y = empirical_stat, fill = Group)) +
    geom_bar(stat = 'identity',color="black") +
    geom_errorbar(aes(ymin = ci_lower, ymax = ci_upper), width = 0.05) +
    geom_point(data = animals_fluency, aes(x= Group, y = Numb_of_Items, group = Group),
               position = position_jitterdodge(0.1),alpha = 0.3)+
    labs(y = 'number of items produced', x = "") +
    theme_few() +
    theme(aspect.ratio = 1, legend.position = 'none')+ annotate("text", x = 2.1, y = 50, label = "animals", 
           hjust = 2, size = 4, fontface = "bold", color = "black") +  scale_y_continuous(limits = c(0, 50))+ 
  scale_colour_paletteer_d("nationalparkcolors::Acadia")+
  scale_color_paletteer_d("nationalparkcolors::Acadia")+
  scale_fill_paletteer_d("nationalparkcolors::Acadia")


#Foods
foods_fluency<- full_foods_fluency%>% drop_na()

#Getting average fluencies per participant
average_foods_fluency = foods_fluency %>% group_by(Subject,Group) %>%
  summarise(average_foods_fluency_count= mean(Numb_of_Items))

#Average fluency per group
foods_group_fluency = average_foods_fluency %>%
  group_by(Group) %>%
  summarise(
    fluency_mean = mean(average_foods_fluency_count),
    fluency_sd = sd(average_foods_fluency_count))
kable(foods_group_fluency)

#Does fluency score differ by Group 
foods_group_lm = lmer(data = foods_fluency, Numb_of_Items~ Group + (1|Subject))
summary(foods_group_lm)
car::Anova(foods_group_lm)


#Combining across animals and foods
comb_fluency <- rbind(animals_fluency,foods_fluency)

#Getting average fluencies per participant
average_comb_fluency = comb_fluency %>% group_by(Subject,Group,domain) %>%
  summarise(average_fluency_count= mean(Numb_of_Items))

#Does fluency differ by group & domain 
comb_group_lm = lmer(data = comb_fluency, Numb_of_Items~ Group*domain + (1|Subject))
summary(comb_group_lm)
car::Anova(comb_group_lm)


foods_numb<-foods_fluency  %>%
  group_by(Group) %>% tidyboot_mean(Numb_of_Items, nboot = 1000, na.rm = T) %>% 
  ggplot(aes(x = Group, y = empirical_stat, fill = Group)) +
    geom_bar(stat = 'identity',color="black") +
    geom_errorbar(aes(ymin = ci_lower, ymax = ci_upper), width = 0.05) +
    geom_point(data = foods_fluency, aes(x= Group, y = Numb_of_Items, group = Group),
               position = position_jitterdodge(0.1),alpha = 0.3)+
    labs(y = 'number of items produced', x = "") +
    theme_few() +
    theme(aspect.ratio = 1, legend.position = 'none')+ annotate("text", x = 2, y = 50, label = "foods", 
           hjust = 2, size = 4, fontface = "bold", color = "black") +
  scale_colour_paletteer_d("nationalparkcolors::Acadia")+
  scale_color_paletteer_d("nationalparkcolors::Acadia")+
  scale_fill_paletteer_d("nationalparkcolors::Acadia")




gridExtra::grid.arrange(animals_numb, foods_numb, ncol=2)


```
#Lexical Analyses
```{r}
#ANIMALS

#getting avg semantic similarity - w2v & s2v
animals_sem_sim_comparison = full_animals_lexical %>% group_by(Subject,Group,dimension,struct) %>%
  summarise(avg_sem_sim = mean(Semantic_Similarity),
            items = n())

#USE similarity
all_struct_animals<-rbind(full_animals_lexical,full_USE_lexical %>% filter(domain=="animals"))

#Avg semantic similarity for each method by participant
animals_USE_sem_sim_comparison <-all_struct_animals %>%group_by(Subject,Group,dimension,struct) %>%
  summarise(avg_sem_sim = mean(Semantic_Similarity),
            items = n())

#JUST W2V/S2V: Does avg semantic similarity differ by group x struct x dim
animals_sem_sim_lm = lmer(data = animals_sem_sim_comparison, avg_sem_sim ~ Group*dimension*struct+ (1|Subject))
summary(animals_sem_sim_lm)
car::Anova(animals_sem_sim_lm)
emmeans(animals_sem_sim_lm,pairwise~dimension*struct,simple="struct")

#Icl USE: Does semantic similarity differ by group x struct
animals_USE_sem_sim_lm = lmer(data = animals_USE_sem_sim_comparison, avg_sem_sim ~ Group*struct+ (1|Subject))
summary(animals_USE_sem_sim_lm)
car::Anova(animals_USE_sem_sim_lm)
emmeans(animals_USE_sem_sim_lm,pairwise~struct,simple="struct")

#getting avg phonological similarity 
animals_phon_sim_comparison = full_animals_lexical %>% group_by(Subject,Group,dimension,struct) %>%
  summarise(avg_phon_sim = mean(Phonological_Similarity),
            items = n())

#LMM failed to converge
#Does avg semantic similarity differ by group 
animals_phon_sim_lm = lm(data = animals_phon_sim_comparison, avg_phon_sim ~ Group)
summary(animals_phon_sim_lm)
car::Anova(animals_phon_sim_lm)
emmeans(animals_phon_sim_lm,pairwise~Group)

#getting avg frequency by Group x dim x struct
animals_freq_comparison = full_animals_lexical %>% group_by(Subject,Group,dimension,struct) %>%
  summarise(avg_freq = mean(Frequency_Value),
            items = n())

#Does avg frequency differ by group 
animals_freq_lm = lmer(data = animals_freq_comparison, avg_freq ~ Group+ (1|Subject))
summary(animals_freq_lm)
car::Anova(animals_freq_lm)


#FOODS

#USE
all_struct_foods<-rbind(full_foods_lexical,full_USE_lexical %>% filter(domain=="foods"))

#JUST W2V & S2V: avg semantic similarity by Group x dim x struct
foods_sem_sim_comparison = full_foods_lexical %>% group_by(Subject,Group,dimension,struct) %>%
  summarise(avg_sem_sim = mean(Semantic_Similarity),
            items = n())

#Incl USE: avg semantic similarity by Group x dim x struct
foods_USE_sem_sim_comparison = all_struct_foods %>% group_by(Subject,Group,dimension,struct) %>%
  summarise(avg_sem_sim = mean(Semantic_Similarity),
            items = n())

#JUST W2V & S2V: Does avg semantic similarity differ by group x struct x dim
foods_sem_sim_lm = lmer(data = foods_sem_sim_comparison, avg_sem_sim ~ Group*struct*dimension+(1|Subject))
summary(foods_sem_sim_lm)
car::Anova(foods_sem_sim_lm)

#INCL USE: Does avg semantic similarity differ by group x struct
foods_USE_sem_sim_lm = lmer(data = foods_USE_sem_sim_comparison, avg_sem_sim ~ Group*struct+(1|Subject))
summary(foods_USE_sem_sim_lm)
car::Anova(foods_USE_sem_sim_lm)
emmeans(foods_USE_sem_sim_lm,pairwise~Group*struct,simple="struct")

#avg phonological similarity by Group x dim x struct
foods_phon_sim_comparison = full_foods_lexical %>% group_by(Subject,Group,dimension,struct) %>%
  summarise(avg_phon_sim = mean(Phonological_Similarity),
            items = n())

#Does avg phon similarity differ by group 
foods_phon_sim_lm = lmer(data = foods_phon_sim_comparison, avg_phon_sim ~ Group+(1|Subject))
summary(foods_phon_sim_lm)
car::Anova(foods_phon_sim_lm)


#avg frequency by Group x dim x struct
foods_freq_comparison = full_foods_lexical %>% group_by(Subject,Group,dimension,struct) %>%
  summarise(avg_freq = mean(Frequency_Value),
            items = n())

#Does avg frequency differ by group 
foods_freq_lm = lmer(data = foods_freq_comparison, avg_freq ~ Group+ (1|Subject))
summary(foods_freq_lm)
car::Anova(foods_freq_lm)

#COMBINED DOMAINS
full_comb_lexical<-rbind(full_animals_lexical,full_foods_lexical,full_USE_lexical)

#Just S2V & W2V
comb_sem_sim_comparison <- full_comb_lexical %>% filter(!struct=="USE")%>%group_by(Subject,Group,domain,dimension,struct) %>%
  summarise(avg_sem_sim = mean(Semantic_Similarity),
            items = n())

#Incl USE
comb_USE_sem_sim_comparison <- full_comb_lexical%>%group_by(Subject,Group,domain,dimension,struct) %>%
  summarise(avg_sem_sim = mean(Semantic_Similarity),
            items = n())


#JUST W2V/S2V:Does avg semantic similarity differ by group x domain x struct x dim
comb_sem_sim_lm = lmer(data = comb_sem_sim_comparison, avg_sem_sim ~ Group*dimension*struct*domain+(1|Subject))
summary(comb_sem_sim_lm)
car::Anova(comb_sem_sim_lm)
emmeans(comb_sem_sim_lm,pairwise~dimension*struct,simple="struct")

#INCL USE: Does avg semantic similarity differ by group x domain x struct 
comb_USE_sem_sim_lm = lmer(data = comb_USE_sem_sim_comparison, avg_sem_sim ~ Group*struct*domain+(1|Subject))
summary(comb_USE_sem_sim_lm)
car::Anova(comb_USE_sem_sim_lm)
emmeans(comb_USE_sem_sim_lm,pairwise~Group*struct,simple="struct")

#avg phonological similarity 
comb_phon_sim_comparison = full_comb_lexical %>% group_by(Subject,Group,domain,dimension,struct) %>%
  summarise(avg_phon_sim = mean(Phonological_Similarity),
            items = n())

#Does phonological similarity differ by group 
comb_phon_sim_lm = lmer(data = comb_phon_sim_comparison, avg_phon_sim ~ Group*domain + (1|Subject))
summary(comb_phon_sim_lm)
car::Anova(comb_phon_sim_lm)
emmeans(comb_phon_sim_lm,pairwise~Group*domain,simple="Group")

#avg frequency by Group x dim x struct
comb_freq_comparison = full_comb_lexical %>% group_by(Subject,Group,domain,dimension,struct) %>%
  summarise(avg_freq = mean(Frequency_Value),
            items = n())

#Does avg frequency differ by group 
comb_freq_lm = lmer(data = comb_freq_comparison, avg_freq ~ Group*domain+(1|Subject))
summary(comb_freq_lm)
car::Anova(comb_freq_lm)
emmeans(comb_freq_lm, pairwise~Group*domain, simple="Group")

comb_USE_sem_sim_comparison %>%
  group_by(Group, domain, struct) %>% 
  tidyboot_mean(avg_sem_sim, nboot = 1000, na.rm = TRUE) %>% 
  mutate(struct = factor(struct, levels = c("w2v", "s2v", "USE"))) %>%  # Set the order of 'struct'
  ggplot(aes(x = Group, y = empirical_stat, fill = struct)) +
    geom_bar(stat = 'identity', color = "black", position = position_dodge(width = 0.9)) +
    geom_errorbar(aes(ymin = ci_lower, ymax = ci_upper), width = 0.2, position = position_dodge(width = 0.9)) +
    labs(y = 'Mean Semantic Similarity', x = "") +
    theme_few() +
    theme(aspect.ratio = 1, 
          legend.position = 'right', 
          axis.text.x = element_text(angle = 45, hjust = 1)) +
    scale_fill_paletteer_d("nationalparkcolors::Acadia") +
    facet_wrap(~ domain) 
comb_phon_sim_comparison  %>%
  group_by(Group,domain) %>% tidyboot_mean(avg_phon_sim, nboot = 1000, na.rm = T) %>% 
  ggplot(aes(x = Group, y = empirical_stat, fill = Group)) +
    geom_bar(stat = 'identity',color="black", position = position_dodge(width = 1)) +
    geom_errorbar(aes(ymin = ci_lower, ymax = ci_upper), width = 0.05) +
    labs(y = 'mean phonological similarity', x = "") +
    theme_few() +
    theme(aspect.ratio = 1, legend.position = 'none',axis.text.x = element_text(angle = 45, hjust = 1))+ 
    facet_wrap(~domain) +
    scale_fill_paletteer_d("nationalparkcolors::Acadia")
comb_freq_comparison  %>%
  group_by(Group,domain) %>% tidyboot_mean(avg_freq, nboot = 1000, na.rm = T) %>% 
  ggplot(aes(x = Group, y = empirical_stat, fill = Group)) +
    geom_bar(stat = 'identity',color="black", position = position_dodge(width =1)) + scale_y_continuous(limits = c(0, 5))+
    geom_errorbar(aes(ymin = ci_lower, ymax = ci_upper), width = 0.05) +
    labs(y = 'mean frequency', x = "") +
    theme_few() +
    theme(aspect.ratio = 1, legend.position = 'none',axis.text.x = element_text(angle = 45, hjust = 1)) +
    facet_wrap(~domain) +
    scale_fill_paletteer_d("nationalparkcolors::Acadia")


#Looking at similarity across structures/dims
desired_order_dim <- c("50", "100", "200","300","512")  
desired_order_struct <- c("w2v", "s2v", "USE")
comp_USE_sem_sim_across <- comb_USE_sem_sim_comparison %>%
  mutate(
    dimension = factor(dimension, levels = desired_order_dim), 
    struct = factor(struct, levels = desired_order_struct)        
  ) %>%
  ggplot(aes(x = struct, y = dimension, fill = avg_sem_sim)) +
  geom_tile() +
  scale_fill_gradient(low = "lightgoldenrod2", high = "aquamarine4", name = "Avg Semantic Similarity") +
  labs(x = "Structure", y = "Dimensions", title = "Domain") +
  theme(
    aspect.ratio = 1,
    plot.title = element_text(hjust = 0.5, size = rel(1.2)),
    axis.text.x = element_text(angle = 45, hjust = 1)
  ) +
  facet_grid(Group ~ domain)
comp_USE_sem_sim_across



```

#Lexical x Fluency Analyses
```{r}
#Similarity by items produced, collapsed across structures and dimensions
comb_fluency %>%
  group_by(Group, domain) %>%
  ggplot(aes(y = Phonological_Similarity_mean, x = Numb_of_Items, group = Group, color = Group)) +
    geom_point(alpha = 0.5,size=5) +
    labs(x = "Number of Items", y = "Mean Phonological Similarity") +
    theme_few() +
    geom_smooth(method = "lm", se = FALSE)+
    theme(aspect.ratio = 1, legend.position = c(0.38, 0.85)) +
    facet_wrap(~domain) +
    scale_color_paletteer_d("nationalparkcolors::Acadia")

comb_fluency%>%group_by(Group,domain)  %>%
  ggplot(aes(y= Semantic_Similarity_mean, x = Numb_of_Items, group = Group, color = Group )) +
  geom_point(alpha = 0.5,size=5)+
  labs(x = "number of items", y = "mean semantic similarity") +
    theme_few() +
    geom_smooth(method = "lm", se = FALSE) +
    theme(aspect.ratio = 1, legend.position = c(.38,0.85)) +
    facet_wrap(~domain) +
    scale_color_paletteer_d("nationalparkcolors::Acadia")


comb_fluency%>%group_by(Group,domain)  %>%
  ggplot(aes(y= Frequency_Value_mean, x = Numb_of_Items, group = Group, color = Group )) +
  geom_point(alpha = 0.5,size=5)+
  labs(x = "number of items", y = "mean frequency") +
    theme_few() +
   geom_smooth(method = "lm", se = FALSE) +
    facet_wrap(~domain) +
    scale_color_paletteer_d("nationalparkcolors::Acadia")


#Does mean phonological similarity x domain type predict numb items produced
comb_psim_model = lmer(data = comb_fluency, 
                Numb_of_Items ~ Phonological_Similarity_mean*Group*domain + (1|Subject))
summary(comb_psim_model)
car::Anova(comb_psim_model)

#Does mean semantic similarity x domain type predict numb items produced
comb_semsim_model = lmer(data = comb_fluency, 
                Numb_of_Items ~ Semantic_Similarity_mean*Group*domain + (1|Subject))
summary(comb_semsim_model)
car::Anova(comb_semsim_model)


#Does mean phonological similarity x domain type predict numb items produced
comb_freq_model = lmer(data = comb_fluency, 
                Numb_of_Items ~ Frequency_Value_mean*Group*domain + (1|Subject))
summary(comb_freq_model)
car::Anova(comb_freq_model)


```

#Clustering Analyses

```{r}
comb_clustering<-rbind(full_animals_fluency,full_foods_fluency)

comb_clusters<- comb_clustering %>%  mutate(fullswitchmethod=Switch_Method)%>%
  separate(Switch_Method, 
           into = c("method", "param1", "param2","param3"), sep = "_",fill = "right")

#Average cluster sizes across switch methods 
comb_cluster_size = comb_clusters %>%
  group_by(Group,method,param1,param2,struct,dimension,domain) %>%
  summarise(
    cluster_mean = mean(Cluster_Size_mean),
    cluster_sd = sd(Cluster_Size_std),
    num_switches = mean(Number_of_Switches),
    sd_switches = mean(Number_of_Switches))
  
#Across Switch Method params
coll_cluster_size = comb_clusters %>%
  group_by(Group,method,struct,dimension,domain) %>%
  summarise(
    cluster_mean = mean(Cluster_Size_mean),
    cluster_sd = sd(Cluster_Size_std),
    num_switches = mean(Number_of_Switches),
    sd_switches = mean(Number_of_Switches))

#cluster size
#animals
desired_order <- c("50", "100", "200","300")  
coll_cluster_size <- coll_cluster_size %>%
  mutate(dimension = factor(dimension, levels = desired_order))  
coll_cluster_size %>% filter(domain=="animals")%>%
  ggplot(aes(dimension, method,fill = cluster_mean)) + 
  geom_tile() +
  facet_grid(~ Group * struct) +
  scale_fill_gradient(low = "lightgoldenrod2", high = "aquamarine4") +
  labs(title="animals",fill = "Avg Cluster Size")+
  theme(
    plot.title = element_text(hjust = 0.5)  
  )

#foods
coll_cluster_size <- coll_cluster_size %>%
  mutate(dimension = factor(dimension, levels = desired_order))  
coll_cluster_size %>% filter(domain=="foods")%>%
  ggplot(aes(dimension, method,fill = cluster_mean)) + 
  geom_tile() +
  facet_grid(~ Group * struct) +
  scale_fill_gradient(low = "lightgoldenrod2", high = "aquamarine4") +
  labs(title="foods",fill = "Avg Cluster Size")+
  theme(
    plot.title = element_text(hjust = 0.5)  
  )

#Number of switches across methods, structures, and dimensions
#animals
coll_cluster_size <- coll_cluster_size %>%
  mutate(dimension = factor(dimension, levels = desired_order))  
coll_cluster_size %>% filter(domain=="animals")%>%
  ggplot(aes(dimension, method,fill = num_switches)) + 
  geom_tile() +
  facet_grid(~ Group * struct) +
  scale_fill_gradient(low = "lightgoldenrod2", high = "aquamarine4") +
  labs(title="animals",fill = "Avg Number of Switches")+
  theme(
    plot.title = element_text(hjust = 0.5)  
  )

#foods
coll_cluster_size <- coll_cluster_size %>%
  mutate(dimension = factor(dimension, levels = desired_order))  
coll_cluster_size %>% filter(domain=="foods")%>%
  ggplot(aes(dimension, method,fill = num_switches)) + 
  geom_tile() +
  facet_grid(~ Group * struct) +
  scale_fill_gradient(low = "lightgoldenrod2", high = "aquamarine4") +
  labs(title="foods",fill = "Avg Number of Switches")+
  theme(
    plot.title = element_text(hjust = 0.5)  
  )

#Does method determining numb of switches sig differ for each Group x domain
comp_switch_lm = lmer(data = comb_clusters, Number_of_Switches ~ Group*method*domain+ (1|Subject))
summary(comp_switch_lm)
car::Anova(comp_switch_lm)
emmeans(comp_switch_lm,pairwise~Group*method,simple="method")

#Across switch methods, does avg number of switches differ by Group, domain, struct, & domain
switch_lm = lmer(data = comb_clusters, Number_of_Switches ~ Group*domain*struct*dimension + (1|Subject))
summary(switch_lm)
car::Anova(switch_lm)
emmeans(switch_lm,pairwise~Group*struct,simple="struct")

#Does cluster size mean sig differ for each method for each Group x domain
comp_clustersize_lm = lmer(data = comb_clusters, Number_of_Switches ~ Group*method*domain+ (1|Subject))
summary(comp_clustersize_lm)
car::Anova(comp_clustersize_lm)
emmeans(comp_clustersize_lm,pairwise~Group*method,simple="method")

#Does cluster size mean differ by Group x domain x struct x dimension
cluster_size_lm = lmer(data = comb_clusters, Cluster_Size_mean ~ Group*domain*struct*dimension + (1|Subject))
summary(cluster_size_lm)
car::Anova(cluster_size_lm)
emmeans(cluster_size_lm,pairwise~Group*struct,simple="struct")

#Does cluster size x Group predict # of switches
switch_clustsize_lm = lmer(data = comb_clusters, Number_of_Switches ~ Group*Cluster_Size_mean + (1|Subject))
summary(switch_clustsize_lm)
car::Anova(switch_clustsize_lm)


comb_clusters %>%
  group_by(Subject,Group,domain) %>%
  summarise(
    cluster_mean = mean(Cluster_Size_mean),
    cluster_sd = sd(Cluster_Size_std),
    num_switches = mean(Number_of_Switches),
    sd_switches = mean(Number_of_Switches)) %>%
  ggplot(aes(x= num_switches, y = cluster_mean, group = Group, color = Group )) +
  geom_point(alpha = 0.5,size=3)+
  labs(y = "mean cluster size", x = "number of switches") +
    theme_few() +
   geom_smooth(method = "lm", se = FALSE) +
    facet_wrap(~domain) +
    scale_color_paletteer_d("nationalparkcolors::Acadia")




```
#Model Analyses

```{r}
#combining model results
agg_model_results = rbind(full_animals_model,full_foods_model) %>% 
  mutate(fullname=Model)%>%
  separate(Model, 
           into = c("forage", "foraging_type", "method", "param1", "param2", "param3"), sep = "_",fill = "right")

#Dropping inf values
agg_model_results_clean <- agg_model_results %>%
  filter(!is.na(Negative_Log_Likelihood_Optimized) & 
         is.finite(Negative_Log_Likelihood_Optimized))

#Summing nLL
agg_model_sum_nLL <- agg_model_results_clean %>% group_by(fullname,foraging_type,method,param1,param2,param3,Group,domain,struct,dimension) %>%
  summarise(sum_nLL = sum(Negative_Log_Likelihood_Optimized)) %>%
  arrange(sum_nLL)


#Does avg nLL differ across Groups x foraging_type
avg_nLL_model = lm(data = agg_model_sum_nLL,sum_nLL ~ Group*foraging_type)
summary(avg_nLL_model)
car::Anova(avg_nLL_model)
emmeans(avg_nLL_model,pairwise~Group*foraging_type, simple="foraging_type")

#best models for each Group x domain
best_models <- agg_model_sum_nLL %>%
  group_by(Group, domain) %>%
  slice_min(order_by = sum_nLL, n = 1) %>%
  ungroup() %>%
   select(-fullname) %>%
  mutate(foraging_type = as.factor(foraging_type),  
         model_type = fct_recode(foraging_type, 
                                  `pstatic` = "phonologicalstatic", 
                                  `plocal` = "phonologicaldynamiclocal",
                                  `pglobal` = "phonologicaldynamicglobal",
                                  `pswitch` = "phonologicaldynamicswitch",
                                  `static` = "static", 
                                  `dynamic` = "dynamic", 
                                  `random` = "random")) %>%
  select(Group,domain,struct,dimension,model_type,method,param1,param2,param3,sum_nLL) 
kable(best_models)

#Getting betas
subject_best_models = agg_model_results_clean %>% 
  group_by(Group, domain,Subject) %>%
  slice_min(Negative_Log_Likelihood_Optimized)

betas  = subject_best_models %>%
  pivot_longer(names_to = "beta", cols = c(Beta_Frequency, Beta_Semantic, Beta_Phonological)) 

#Does use of semantic similarity differ across Groups x domains
beta_semantic_model = lmer(data = betas %>% filter(beta == "Beta_Semantic"), value ~ Group*domain +(1|Subject))
summary(beta_semantic_model)
car::Anova(beta_semantic_model)
emmeans(beta_semantic_model,pairwise~Group*domain, simple="Group")

#Does use of frequency differ across Groups x domains
beta_freq_model = lmer(data = betas %>% filter(beta == "Beta_Frequency"), value ~ Group*domain +(1|Subject))
summary(beta_freq_model)
car::Anova(beta_freq_model)
emmeans(beta_freq_model,pairwise~Group*domain, simple="Group")

#Does use of phonological similarity differ across Groups x domains
beta_phon_model = lmer(data = betas %>% filter(beta == "Beta_Phonological"), value ~ Group*domain+(1|Subject))
summary(beta_phon_model)
car::Anova(beta_phon_model)
emmeans(beta_phon_model,pairwise~Group*domain, simple="Group")

betas %>% 
  group_by(Group, beta,domain) %>%
  tidyboot_mean(value, nboot = 1000, na.rm = T) %>%
  separate(beta, into = c("b", "beta"))%>%
  mutate(beta = tolower(beta),
         beta = fct_recode(beta, 
                    `semantic\nsimilarity`="semantic", `phonological\nsimilarity` = "phonological",
                           `frequency` = "frequency"))%>%
  mutate(beta = fct_relevel(beta, "semantic\nsimilarity", "frequency", "phonological\nsimilarity")) %>%
  ggplot(aes(x = beta, y = empirical_stat, group = Group, fill = Group)) +
    geom_bar(stat = 'identity', position = "dodge") +
    geom_errorbar(aes(ymin = ci_lower, ymax = ci_upper), width = 0, position =  position_dodge(0.9)) +
    labs(y = bquote(beta ~ "(parameter salience)"), x = "") +
    theme_few() +
    theme(aspect.ratio = 1, legend.position = c(0.87,0.86))+ facet_wrap(~domain)+
    scale_fill_paletteer_d("nationalparkcolors::Acadia")

#Looking at nLL's across methods
agg_model_sum_nLL_lab <- agg_model_sum_nLL %>%
  mutate(foraging_type = as.factor(foraging_type),  
         model_type = fct_recode(foraging_type, 
                                  `pstatic` = "phonologicalstatic", 
                                  `plocal` = "phonologicaldynamiclocal",
                                  `pglobal` = "phonologicaldynamicglobal",
                                  `pswitch` = "phonologicaldynamicswitch",
                                  `static` = "static", 
                                  `dynamic` = "dynamic", 
                                  `random` = "random"))

models <-c("dynamic","pswitch","pglobal","plocal")
methods <- c("norms", "simdrop", "delta", "multimodal", "multimodaldelta")
coll_agg_model_sum_nLL <- agg_model_sum_nLL_lab %>%
  filter(model_type %in% models) %>%  
  filter(method %in% methods) 
  
coll_agg_model_sum_nLL %>% ggplot(aes(x = method, y = model_type, fill = `sum_nLL`)) +
  geom_tile()+
  scale_fill_gradient2(midpoint =3450) +
  labs(x = "", y = "foraging model", title = "domain") +
  theme(aspect.ratio = 1,
        plot.title = element_text(hjust = 0.5, size = rel(1.2)),
        axis.text.x = element_text(angle = 45, hjust = 1))+ facet_grid(Group~domain)+scale_fill_gradient(low = "lightgoldenrod2", high =     "aquamarine4")


#Best models across particpants
subject_best_models = subject_best_models %>%
  mutate(model_type = fct_recode(foraging_type, 
                                    `pstatic` = "phonologicalstatic", 
                                    `plocal` = "phonologicaldynamiclocal",
                                    `pglobal` = "phonologicaldynamicglobal",
                                    `pswitch` = "phonologicaldynamicswitch",
                                    `static` = "static", `dynamic` = "dynamic", `random` = "random"))
  
subject_best_models %>%
    group_by(Group, domain,model_type) %>%
    count() %>%
    ggplot(aes(x = Group, y = n, group = model_type, fill = model_type)) +
    geom_col() +
    labs(y = "Number of Participants", x = "", fill = "Best Model Type") +  
    theme_few() +
    scale_fill_calc() +
    theme(aspect.ratio = 1, legend.position = "right") +facet_wrap(~domain)+
    scale_fill_paletteer_d("nationalparkcolors::Acadia")
```
#Exploring Best Models

```{r}
#overall best model
overall_best_model <- agg_model_sum_nLL %>% ungroup() %>%
  arrange(sum_nLL) %>%       
  slice(1) %>%                
  mutate(foraging_type = as.factor(foraging_type),  
         model_type = fct_recode(foraging_type, 
                                  `pstatic` = "phonologicalstatic", 
                                  `plocal` = "phonologicaldynamiclocal",
                                  `pglobal` = "phonologicaldynamicglobal",
                                  `pswitch` = "phonologicaldynamicswitch",
                                  `static` = "static", 
                                  `dynamic` = "dynamic", 
                                  `random` = "random")) %>%
  mutate(full_method=paste(method,param1,param2,param3,sep="_"))%>%
  select(model_type, full_method,struct, dimension,  sum_nLL)

kable(overall_best_model)

#Avg cluster size and num switches for best switch method
best_method<- overall_best_model$full_method
best_clusters = comb_clustering %>% filter(Switch_Method==best_method) %>%filter(Switch_Method==best_type)
  summarise(
    cluster_mean = mean(Cluster_Size_mean),
    cluster_sd = sd(Cluster_Size_std),
    num_switches = mean(Number_of_Switches),
    sd_switches = sd(Number_of_Switches))
kable(best_clusters)


#Betas for overall best model
best_type <- as.character(overall_best_model$model_type)

best_model_betas <- agg_model_results_clean %>%
  mutate(full_method = paste(method, param1, param2, param3, sep = "_")) %>%
  mutate(foraging_type = as.factor(foraging_type),  
         model_type = fct_recode(foraging_type, 
                                 `pstatic` = "phonologicalstatic", 
                                 `plocal` = "phonologicaldynamiclocal",
                                 `pglobal` = "phonologicaldynamicglobal",
                                 `pswitch` = "phonologicaldynamicswitch",
                                 `static` = "static", 
                                 `dynamic` = "dynamic", 
                                 `random` = "random")) %>%
  filter(full_method == best_method) %>%
  filter(as.character(model_type) == best_type)

#Betas for each participant for best model
best_beta_values  = best_model_betas %>% 
  pivot_longer(names_to = "beta", cols = c(Beta_Frequency, Beta_Semantic, Beta_Phonological)) 

#Best model betas across participants
best_beta_values  %>% 
  group_by(Group, beta,domain) %>%
  tidyboot_mean(value, nboot = 1000, na.rm = T) %>%
  separate(beta, into = c("b", "beta"))%>%
  mutate(beta = tolower(beta),
         beta = fct_recode(beta, 
                    `semantic\nsimilarity`="semantic", `phonological\nsimilarity` = "phonological",
                           `frequency` = "frequency"))%>%
  mutate(beta = fct_relevel(beta, "semantic\nsimilarity", "frequency", "phonological\nsimilarity")) %>%
  ggplot(aes(x = beta, y = empirical_stat, group = Group, fill = Group)) +
    geom_bar(stat = 'identity', position = "dodge") +
    geom_errorbar(aes(ymin = ci_lower, ymax = ci_upper), width = 0, position =  position_dodge(0.9)) +
    labs(y = bquote(beta ~ "(parameter salience)"), x = "") +
    theme_few() +
    theme(aspect.ratio = 1, legend.position = c(0.62,0.86))+ facet_wrap(~domain)+
    scale_fill_paletteer_d("nationalparkcolors::Acadia")


#Beta testing
#Does use of semantic similarity differ across Groups x domains
best_beta_semantic_model = lmer(data = best_beta_values %>% filter(beta == "Beta_Semantic"), value ~ Group*domain +(1|Subject))
summary(best_beta_semantic_model)
car::Anova(best_beta_semantic_model)
emmeans(best_beta_semantic_model,pairwise~Group*domain, simple="domain")

#Does use of frequency differ across Groups x domains
best_beta_freq_model = lmer(data = best_beta_values %>% filter(beta == "Beta_Frequency"), value ~ Group*domain +(1|Subject))
summary(best_beta_freq_model)
car::Anova(best_beta_freq_model)
emmeans(best_beta_freq_model,pairwise~Group*domain, simple="domain")

#Does use of phonological similarity differ across Groups x domains
best_beta_phon_model = lmer(data = best_beta_values %>% filter(beta == "Beta_Phonological"), value ~ Group*domain+(1|Subject))
summary(best_beta_phon_model)
car::Anova(best_beta_phon_model)
```

#Best models for each Group x domain
```{r}
#best models for each Group x domain
best_models <- agg_model_sum_nLL %>%
  group_by(Group, domain) %>%
  slice_min(order_by = sum_nLL, n = 1) %>%
  mutate(foraging_type = as.factor(foraging_type),  
         model_type = fct_recode(foraging_type, 
                                  `pstatic` = "phonologicalstatic", 
                                  `plocal` = "phonologicaldynamiclocal",
                                  `pglobal` = "phonologicaldynamicglobal",
                                  `pswitch` = "phonologicaldynamicswitch",
                                  `static` = "static", 
                                  `dynamic` = "dynamic", 
                                  `random` = "random")) %>%
  mutate(full_method=paste(method,param1,param2,param3,sep="_"))%>%
  select(Group, domain,model_type, full_method,struct, dimension,  sum_nLL)
kable(best_models)


#Avg cluster size and num switches for best models for each group x domain
best_method_nh_a <- best_models$full_method[1]
best_method_nh_f <- best_models$full_method[2]
best_method_ci_a <- best_models$full_method[3]
best_method_ci_f <- best_models$full_method[4]

nh_a_clusters = comb_clustering %>% filter(Group=="normal hearing")%>% filter(domain=="animals") %>% filter(Switch_Method==best_method_nh_a) %>%
  summarise(
    cluster_mean = mean(Cluster_Size_mean),
    cluster_sd = sd(Cluster_Size_std),
    num_switches = mean(Number_of_Switches),
    sd_switches = sd(Number_of_Switches)) %>%
  mutate(Group="NH") %>% mutate(domain="animals") %>% mutate(best_method=best_method_nh_a) %>%
  select(Group,domain,best_method,cluster_mean,cluster_sd,num_switches,sd_switches)

nh_f_clusters = comb_clustering %>% filter(Group=="normal hearing")%>% filter(domain=="foods") %>%filter(Switch_Method==best_method_nh_f) %>%
  summarise(
    cluster_mean = mean(Cluster_Size_mean),
    cluster_sd = sd(Cluster_Size_std),
    num_switches = mean(Number_of_Switches),
    sd_switches = sd(Number_of_Switches)) %>%
  mutate(Group="NH") %>% mutate(domain="foods") %>% mutate(best_method=best_method_nh_f) %>%
  select(Group,domain,best_method,cluster_mean,cluster_sd,num_switches,sd_switches)

ci_a_clusters = comb_clustering %>% filter(Group=="cochlear implant")%>% filter(domain=="animals") %>% filter(Switch_Method==best_method_ci_a) %>%
  summarise(
    cluster_mean = mean(Cluster_Size_mean),
    cluster_sd = sd(Cluster_Size_std),
    num_switches = mean(Number_of_Switches),
    sd_switches = sd(Number_of_Switches)) %>%
  mutate(Group="CI") %>% mutate(domain="animals") %>% mutate(best_method=best_method_ci_a) %>%
  select(Group,domain,best_method,cluster_mean,cluster_sd,num_switches,sd_switches)


ci_f_clusters = comb_clustering %>% filter(Group=="cochlear implant")%>% filter(domain=="foods") %>% filter(Switch_Method==best_method_ci_f) %>%
  summarise(
    cluster_mean = mean(Cluster_Size_mean),
    cluster_sd = sd(Cluster_Size_std),
    num_switches = mean(Number_of_Switches),
    sd_switches = sd(Number_of_Switches)) %>%
  mutate(Group="CI") %>% mutate(domain="foods") %>% mutate(best_method=best_method_ci_f) %>%
  select(Group,domain,best_method,cluster_mean,cluster_sd,num_switches,sd_switches)

comb_best_clusters<-rbind(nh_a_clusters,nh_f_clusters,ci_a_clusters,ci_f_clusters) %>% arrange(Group,domain)
kable(comb_best_clusters)

#Full participant data
full_nh_a_clusters = comb_clustering %>% filter(Group=="normal hearing")%>% filter(domain=="animals") %>% filter(Switch_Method==best_method_nh_a)

full_nh_f_clusters = comb_clustering %>% filter(Group=="normal hearing")%>% filter(domain=="foods") %>%filter(Switch_Method==best_method_nh_f) 

full_ci_a_clusters = comb_clustering %>% filter(Group=="cochlear implant")%>% filter(domain=="animals") %>% filter(Switch_Method==best_method_ci_a)

full_ci_f_clusters = comb_clustering %>% filter(Group=="cochlear implant")%>% filter(domain=="foods") %>% filter(Switch_Method==best_method_ci_f)

full_comb_best_clusters<-rbind(full_nh_a_clusters,full_nh_f_clusters,full_ci_a_clusters,full_ci_f_clusters) %>% arrange(Group,domain)

#When using the best method, does avg cluster mean differ by Group x domain
best_cluster_size_lm = lmer(data = full_comb_best_clusters, Cluster_Size_mean ~ Group*domain + (1|Subject))
summary(best_cluster_size_lm)
car::Anova(best_cluster_size_lm)
emmeans(best_cluster_size_lm,pairwise~Group*domain)

#When using the best method, does avg numb switches differ by Group x domain
best_switch_numb_lm = lmer(data = full_comb_best_clusters, Number_of_Switches ~ Group*domain + (1|Subject))
summary(best_switch_numb_lm)
car::Anova(best_switch_numb_lm)
emmeans(best_switch_numb_lm,pairwise~Group*domain)


best_cluster<-full_comb_best_clusters %>%
  group_by(Group, domain) %>% 
  tidyboot_mean(Cluster_Size_mean, nboot = 1000, na.rm = TRUE) %>% 
  ggplot(aes(x = domain, y = empirical_stat, fill = Group)) +
    geom_bar(stat = 'identity', color = "black", position = position_dodge(width = 0.9)) +
    geom_errorbar(aes(ymin = ci_lower, ymax = ci_upper), width = 0.2, position = position_dodge(width = 0.9)) +
    labs(y = 'Avg Cluster Size', x = "") +
    theme_few() +
    theme(aspect.ratio = 1, 
          legend.position = 'right', 
          axis.text.x = element_text(angle = 45, hjust = 1)) +
    scale_fill_paletteer_d("nationalparkcolors::Acadia") 

best_switches<-full_comb_best_clusters %>%
  group_by(Group, domain) %>% 
  tidyboot_mean(Number_of_Switches, nboot = 1000, na.rm = TRUE) %>% 
  ggplot(aes(x = domain, y = empirical_stat, fill = Group)) +
    geom_bar(stat = 'identity', color = "black", position = position_dodge(width = 0.9)) +
    geom_errorbar(aes(ymin = ci_lower, ymax = ci_upper), width = 0.2, position = position_dodge(width = 0.9)) +
    labs(y = 'Avg Number of Switches', x = "") +
    theme_few() +
    theme(aspect.ratio = 1, 
          legend.position = 'right', 
          axis.text.x = element_text(angle = 45, hjust = 1)) +
    scale_fill_paletteer_d("nationalparkcolors::Acadia") 

gridExtra::grid.arrange(best_cluster, best_switches, ncol=2)


####CHECK ABOVE AND THEN ADD BETA ANALYSES HERE
```





